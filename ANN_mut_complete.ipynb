{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YK4yrsXu7IfD",
        "outputId": "a9a4656e-8cf3-4421-bb09-938001e5edd6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/content/gdrive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd 'gdrive/MyDrive/Colab Notebooks/CHL/semester-project'\n",
        "%ls"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lldVCbxQ7e_G",
        "outputId": "813ff295-aecc-48b7-921c-e7ccde53a31f"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Errno 2] No such file or directory: 'gdrive/MyDrive/Colab Notebooks/CHL/semester-project'\n",
            "/content/gdrive/MyDrive/Colab Notebooks/CHL/semester-project\n",
            "ANN.ipynb  \u001b[0m\u001b[01;34mdataset\u001b[0m/\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Libraries\n"
      ],
      "metadata": {
        "id": "u8T3fg7TtN3K"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from tensorflow.keras.wrappers.scikit_learn import KerasClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "import numpy as np\n",
        "import pandas as pd\n"
      ],
      "metadata": {
        "id": "tMUeP08r7sle"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "np.random.seed(42)"
      ],
      "metadata": {
        "id": "BymXySuxvIfR"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data Processing"
      ],
      "metadata": {
        "id": "i8XFNf7fuzjy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv(\"dataset/mutationsComplete.csv\", index_col=False)\n",
        "df = df.drop(\"Unnamed: 0\", axis=1)\n",
        "# print(df.head())\n",
        "\n",
        "# exit()\n",
        "\n",
        "df = df.loc[:, ~df.columns.isin(['AccessionNumber', '1stpfs event', 'dpfs', 'dos'])]\n",
        "# df = df[df[\"safety\"]==1] #select safety analysis\n",
        "# df = df.drop('PatientCode',axis=1) #drop one row with Nan value\n",
        "# df = df[~df.isin([-99]).any(axis=1)] #drop any rows with -99 value\n",
        "# # For now, remove all rows with Nan values\n",
        "# # remove rows with NaN values, it's actually only one row\n",
        "# df = df.dropna()\n",
        "\n",
        "print(len(df))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5FOa_6vsuyx5",
        "outputId": "3857c557-1dfb-44b6-a6c0-3040356d9ad3"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "296\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train, test = train_test_split(df, test_size=0.2, random_state=42)\n",
        "# train, validation = train_test_split(train, test_size=0.1, random_state=42)"
      ],
      "metadata": {
        "id": "8zQ2tn5_vQzB"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Separate the target variable from the features\n",
        "y_train = train['os event']\n",
        "X_train = train.drop('os event', axis=1)\n",
        "# y_val = validation[\"os event\"]\n",
        "# X_val = validation.drop(\"os event\", axis=1)\n",
        "y_test = test['os event']\n",
        "X_test = test.drop('os event', axis=1)"
      ],
      "metadata": {
        "id": "izgzyIaYvXHk"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Normalizing Data"
      ],
      "metadata": {
        "id": "tGOkwJHRvd9A"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "scaler = MinMaxScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "# X_val = scaler.transform(X_val)\n",
        "X_test = scaler.transform(X_test)"
      ],
      "metadata": {
        "id": "cP4OfFe-vZ46"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ANN Model"
      ],
      "metadata": {
        "id": "NjjASRyRzHiV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "early_stopping_monitor = EarlyStopping(\n",
        "    monitor=\"val_loss\",\n",
        "    verbose=1,\n",
        "    patience=5,\n",
        "    restore_best_weights=True\n",
        ")"
      ],
      "metadata": {
        "id": "jNhhLsYF82i8"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_features = X_train.shape[1]\n",
        "\n",
        "def create_model():\n",
        "  model = tf.keras.Sequential()\n",
        "\n",
        "  model.add(tf.keras.Input((num_features,)))\n",
        "  model.add(tf.keras.layers.Dense(8))\n",
        "  model.add(tf.keras.layers.Activation(\"relu\"))\n",
        "  model.add(tf.keras.layers.Dense(16))\n",
        "  model.add(tf.keras.layers.Activation(\"relu\"))\n",
        "  model.add(tf.keras.layers.Dense(16))\n",
        "  model.add(tf.keras.layers.Activation(\"relu\"))\n",
        "  model.add(tf.keras.layers.Dense(8))\n",
        "  model.add(tf.keras.layers.Activation(\"relu\"))\n",
        "  model.add(tf.keras.layers.Dense(1))\n",
        "  model.add(tf.keras.layers.Activation(\"sigmoid\"))\n",
        "\n",
        "  model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "  return model"
      ],
      "metadata": {
        "id": "2rXB9gAQxwwK"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = KerasClassifier(build_fn=create_model, verbose=1)\n",
        "# define the grid search parameters\n",
        "batch_size = [4, 8, 16, 32, 64]\n",
        "epochs = [5, 7, 10, 12, 15, 17, 20]\n",
        "param_grid = dict(batch_size=batch_size, epochs=epochs)\n",
        "\n",
        "\n",
        "# model_history = model.fit(X_train, y_train, batch_size=32, epochs=20, validation_data=(X_val, y_val), callbacks=[early_stopping_monitor])\n",
        "\n",
        "\n",
        "grid = GridSearchCV(estimator=model, param_grid=param_grid, n_jobs=-1, cv=3)\n",
        "grid_result = grid.fit(X_train, y_train)\n",
        "# summarize results\n",
        "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
        "means = grid_result.cv_results_['mean_test_score']\n",
        "stds = grid_result.cv_results_['std_test_score']\n",
        "params = grid_result.cv_results_['params']\n",
        "for mean, stdev, param in zip(means, stds, params):\n",
        "    print(\"%f (%f) with: %r\" % (mean, stdev, param))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lyBnf7YpxyMk",
        "outputId": "e2a14dcc-a118-45f9-fb48-495ddf4429bc"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-37-7a9a9f458f0e>:1: DeprecationWarning: KerasClassifier is deprecated, use Sci-Keras (https://github.com/adriangb/scikeras) instead. See https://www.adriangb.com/scikeras/stable/migration.html for help migrating.\n",
            "  model = KerasClassifier(build_fn=create_model, verbose=1)\n",
            "/usr/local/lib/python3.10/dist-packages/joblib/externals/loky/process_executor.py:700: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "8/8 [==============================] - 2s 5ms/step - loss: 0.6927 - accuracy: 0.6144\n",
            "Epoch 2/5\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.6908 - accuracy: 0.6737\n",
            "Epoch 3/5\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.6870 - accuracy: 0.6737\n",
            "Epoch 4/5\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.6791 - accuracy: 0.6737\n",
            "Epoch 5/5\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.6697 - accuracy: 0.6737\n",
            "Best: 0.681976 using {'batch_size': 32, 'epochs': 5}\n",
            "0.673429 (0.054205) with: {'batch_size': 4, 'epochs': 5}\n",
            "0.656497 (0.047484) with: {'batch_size': 4, 'epochs': 7}\n",
            "0.622471 (0.069245) with: {'batch_size': 4, 'epochs': 10}\n",
            "0.614519 (0.019442) with: {'batch_size': 4, 'epochs': 12}\n",
            "0.601753 (0.032470) with: {'batch_size': 4, 'epochs': 15}\n",
            "0.631234 (0.022756) with: {'batch_size': 4, 'epochs': 17}\n",
            "0.635562 (0.007333) with: {'batch_size': 4, 'epochs': 20}\n",
            "0.673429 (0.054205) with: {'batch_size': 8, 'epochs': 5}\n",
            "0.631234 (0.046045) with: {'batch_size': 8, 'epochs': 7}\n",
            "0.576490 (0.095158) with: {'batch_size': 8, 'epochs': 10}\n",
            "0.593314 (0.084143) with: {'batch_size': 8, 'epochs': 12}\n",
            "0.635454 (0.027950) with: {'batch_size': 8, 'epochs': 15}\n",
            "0.673483 (0.054738) with: {'batch_size': 8, 'epochs': 17}\n",
            "0.618576 (0.028210) with: {'batch_size': 8, 'epochs': 20}\n",
            "0.673429 (0.054205) with: {'batch_size': 16, 'epochs': 5}\n",
            "0.681921 (0.053677) with: {'batch_size': 16, 'epochs': 7}\n",
            "0.648058 (0.041557) with: {'batch_size': 16, 'epochs': 10}\n",
            "0.664990 (0.045335) with: {'batch_size': 16, 'epochs': 12}\n",
            "0.567943 (0.061892) with: {'batch_size': 16, 'epochs': 15}\n",
            "0.673429 (0.054205) with: {'batch_size': 16, 'epochs': 17}\n",
            "0.652331 (0.066856) with: {'batch_size': 16, 'epochs': 20}\n",
            "0.681976 (0.043277) with: {'batch_size': 32, 'epochs': 5}\n",
            "0.673429 (0.054205) with: {'batch_size': 32, 'epochs': 7}\n",
            "0.669209 (0.053744) with: {'batch_size': 32, 'epochs': 10}\n",
            "0.605918 (0.103381) with: {'batch_size': 32, 'epochs': 12}\n",
            "0.673429 (0.054205) with: {'batch_size': 32, 'epochs': 15}\n",
            "0.631180 (0.073292) with: {'batch_size': 32, 'epochs': 17}\n",
            "0.660716 (0.058991) with: {'batch_size': 32, 'epochs': 20}\n",
            "0.673429 (0.054205) with: {'batch_size': 64, 'epochs': 5}\n",
            "0.673429 (0.054205) with: {'batch_size': 64, 'epochs': 7}\n",
            "0.673429 (0.054205) with: {'batch_size': 64, 'epochs': 10}\n",
            "0.627015 (0.040093) with: {'batch_size': 64, 'epochs': 12}\n",
            "0.669209 (0.053744) with: {'batch_size': 64, 'epochs': 15}\n",
            "0.677648 (0.059046) with: {'batch_size': 64, 'epochs': 17}\n",
            "0.618035 (0.101726) with: {'batch_size': 64, 'epochs': 20}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# model.summary()\n",
        "print(\"Tuned ANN Parameters: {}\".format(grid_result.best_params_))\n",
        "print(\"Best score on validation is {}\".format(grid_result.best_score_))\n",
        "grid_predictions = grid_result.predict(X_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HQPVBSFI4u6-",
        "outputId": "1c1022d0-941f-4aaa-ef51-93b6ab6d0ee1"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tuned ANN Parameters: {'batch_size': 32, 'epochs': 5}\n",
            "Best score on validation is 0.6819755434989929\n",
            "2/2 [==============================] - 0s 3ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "accuracy_score(y_test, grid_predictions)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8OO6--bL4w2w",
        "outputId": "22080375-cd10-4e80-800f-1abccafe94a7"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.7166666666666667"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "PlPIA6Vz6O1-"
      },
      "execution_count": 39,
      "outputs": []
    }
  ]
}